{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Low Rank Matrix Factorization\n",
    "\n",
    "## Formulation\n",
    "Let's assume that our system has $I_{user}$ users and $J_{movie}$ movies. We assign $K_{latent}$ features to each user and movie in the system. We can construct a matrix factorization as follows:\n",
    "\n",
    "$$\n",
    "\\begin{vmatrix}\n",
    "x_{0,0} & x_{0,1} & x_{0, 2} & ... & x_{0, K} \\\\\n",
    "x_{1,0} & ...     & ...      & ... & ...      \\\\\n",
    "x_{2,0} & ...     & ...      & ... & ...      \\\\\n",
    "...     & ...     & ...      & ... & ...      \\\\\n",
    "x_{I,0} & ...     & ...      & ... & x_{I, K}\n",
    "\\end{vmatrix}\n",
    "\\begin{vmatrix}\n",
    "\\theta_{0,0} & \\theta_{0,1} & \\theta_{0, 2} & ... & \\theta_{0, K} \\\\\n",
    "\\theta_{1,0} & ...     & ...      & ... & ...      \\\\\n",
    "\\theta_{2,0} & ...     & ...      & ... & ...      \\\\\n",
    "...     & ...     & ...      & ... & ...      \\\\\n",
    "\\theta_{J,0} & ...     & ...      & ... & \\theta_{J, K}\n",
    "\\end{vmatrix}^{T}\n",
    "=\n",
    "\\begin{vmatrix}\n",
    "r_{0,0} & r_{0,1} & r_{0, 2} & ... & r_{0, J} \\\\\n",
    "r_{1,0} & ...     & ...      & ... & ...      \\\\\n",
    "r_{2,0} & ...     & ...      & ... & ...      \\\\\n",
    "...     & ...     & ...      & ... & ...      \\\\\n",
    "r_{I,0} & ...     & ...      & ... & r_{I, J}\n",
    "\\end{vmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "X\\Theta^{T} = \\hat{R}\n",
    "$$\n",
    "\n",
    "$X$ represents the latent feature matrix for all users in our system. $\\Theta$ represents the latent feature matrix for all all movies in our system. The matrix product of $X$ and $\\Theta^{T}$ is the model predicated rating. Let $R$ represents the actual rating we received from the MovieLens dataset. For every missing value in $R$, we will place them with average rating each movie received from the poll of users. Then we define the loss function as follows:\n",
    "\n",
    "$$\n",
    "L_{X, \\Theta} = \\frac{1}{2}\\Sigma_{i,j} (X\\Theta^{T} - R)^{2} + \\frac{\\lambda}{2}\\Sigma_{i, k}X^{2} + \\frac{\\lambda}{2}\\Sigma_{j, k}\\Theta^{2}\n",
    "$$\n",
    "\n",
    "The optimization objective here is to minimize the loss function above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partial Derivatives & Gradients\n",
    "\n",
    "Recall that the output of our low-rank matrices model is $\\hat{R}$ and let's find the gradient of $L$ with respect to $\\hat{R}$ first. The $\\frac{1}{2}$ term will get canceled out by the square term.\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial \\hat{R}} = \\hat{R} - R\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\hat{R} = X\\Theta^{T}\n",
    "$$\n",
    "\n",
    "Now let's figure out the gradient of $\\hat{R}$ with respect to $X$ and $\\Theta$:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\hat{R}}{\\partial X} = \\Theta^{T}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\hat{R}}{\\partial \\Theta} = X\n",
    "$$\n",
    "\n",
    "Using chain rule, we can then do the following:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial X} = \\frac{\\partial L}{\\partial \\hat{R}}\\frac{\\partial \\hat{R}}{\\partial X}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial \\Theta} = \\frac{\\partial L}{\\partial \\hat{R}}\\frac{\\partial \\hat{R}}{\\partial \\Theta}\n",
    "$$\n",
    "\n",
    "In Python,\n",
    "```python\n",
    "# Denote U as the user latent feature matrix and M as the movie latent feature matrix\n",
    "pred = np.dot(U, M.T)\n",
    "grad_pred = pred - R \n",
    "grad_u = np.dot(grad_pred, M)+ (reg * U)\n",
    "grad_m = np.dot(grad_pred.T, U) + (reg * M)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def loss(U, M, R, reg=0.0):\n",
    "    \"\"\"Compute loss\n",
    "    \n",
    "    :param U: User latent feature matrix, there are I movies and K features\n",
    "    :type U: numpy 2-d array\n",
    "    :param M: Movie latent feature matrix, there are J movies and K features\n",
    "    :type M: numpy 2-d array\n",
    "    :param R: Rating matrix, i-index represents user and j-index represents movie\n",
    "    :type R: numpy 2-d array\n",
    "    :param reg: Regularization strength\n",
    "    :type reg: float\n",
    "    \"\"\"\n",
    "    diff = np.dot(U, M.T) - R\n",
    "    loss = 0.5 * np.sum(diff * diff)\n",
    "    loss += reg * np.sum(U * U) / 2\n",
    "    loss += reg * np.sum(M * M) / 2\n",
    "    return loss\n",
    "\n",
    "\n",
    "def rel_error(X, Y):\n",
    "    \"\"\"Compute maximum relative error\n",
    "    \n",
    "    :param X: Matrix of the same shape as Y\n",
    "    :type X: numpy array\n",
    "    :param Y: Matrix of the same shape as X\n",
    "    :type Y: numpy array\n",
    "    \"\"\"\n",
    "    return np.max(np.abs(X - Y) / (np.maximum(1e-8, np.abs(X) + np.abs(Y))))\n",
    "\n",
    "\n",
    "def compute_grad(U, M, R, reg=0.0):\n",
    "    \"\"\"Compute gradients for U and M\n",
    "    \n",
    "    :param U: User latent feature matrix, there are I movies and K features\n",
    "    :type U: numpy 2-d array\n",
    "    :param M: Movie latent feature matrix, there are J movies and K features\n",
    "    :type M: numpy 2-d array\n",
    "    :param R: Rating matrix, i-index represents user and j-index represents movie\n",
    "    :type R: numpy 2-d array\n",
    "    :param reg: Regularization strength\n",
    "    :type reg: float\n",
    "    \"\"\"\n",
    "    u_grad = np.zeros(U.shape)\n",
    "    m_grad = np.zeros(M.shape)\n",
    "    \n",
    "    num_user, lat_dim = U.shape\n",
    "    num_movie, lat_dim = M.shape\n",
    "    \n",
    "    diff = np.dot(U, M.T) - R\n",
    "    for i in range(num_user):\n",
    "        u_grad[i] = np.sum(diff[i].reshape(num_movie, 1) * M, axis=0) + (reg * U[i])\n",
    "\n",
    "    for j in range(num_movie):\n",
    "        m_grad[j] = np.sum(diff.T[j].reshape(num_user, 1) * U, axis=0) + (reg * M[j])\n",
    "        \n",
    "    return u_grad, m_grad\n",
    "\n",
    "\n",
    "def compute_grad_vectorized(U, M, R, reg=0.0):\n",
    "    \"\"\"Compute gradients for U and M\n",
    "    \n",
    "    :param U: User latent feature matrix, there are I movies and K features\n",
    "    :type U: numpy 2-d array\n",
    "    :param M: Movie latent feature matrix, there are J movies and K features\n",
    "    :type M: numpy 2-d array\n",
    "    :param R: Rating matrix, i-index represents user and j-index represents movie\n",
    "    :type R: numpy 2-d array\n",
    "    :param reg: Regularization strength\n",
    "    :type reg: float\n",
    "    \"\"\"\n",
    "    grad_out = np.dot(U, M.T) - R \n",
    "    grad_u = np.dot(grad_out, M)+ (reg * U)\n",
    "    grad_m = np.dot(grad_out.T, U) + (reg * M)\n",
    "    return grad_u, grad_m\n",
    "\n",
    "\n",
    "def compute_num_grad(U, M, R, loss_func, reg=0.0, h=1e-5):\n",
    "    \"\"\"Compute numerical gradients for U and M\n",
    "    \n",
    "    :param U: User latent feature matrix, there are I movies and K features\n",
    "    :type U: numpy 2-d array\n",
    "    :param M: Movie latent feature matrix, there are J movies and K features\n",
    "    :type M: numpy 2-d array\n",
    "    :param R: Rating matrix, i-index represents user and j-index represents movie\n",
    "    :type R: numpy 2-d array\n",
    "    :param reg: Regularization strength\n",
    "    :type reg: float\n",
    "    \"\"\"\n",
    "    num_grad_u = np.zeros(U.shape)\n",
    "    num_grad_m = np.zeros(M.shape)\n",
    "    \n",
    "    U_dim, L_dim = U.shape\n",
    "    M_dim, L_dim = M.shape\n",
    "    \n",
    "    for i in range(U_dim):\n",
    "        for k in range(L_dim):\n",
    "            old_val = U[i][k]\n",
    "            \n",
    "            U[i][k] = old_val + h\n",
    "            fuph = loss_func(U, M, R, reg)\n",
    "            \n",
    "            U[i][k] = old_val - h\n",
    "            fumh = loss_func(U, M, R, reg)\n",
    "            \n",
    "            U[i][k] = old_val\n",
    "            num_grad_u[i][k] = (fuph - fumh) / (2 * h)\n",
    "    \n",
    "    for j in range(M_dim):\n",
    "        for k in range(L_dim):\n",
    "            old_val = M[j][k]\n",
    "            \n",
    "            M[j][k] = old_val + h\n",
    "            fmph = loss_func(U, M, R, reg)\n",
    "            \n",
    "            M[j][k] = old_val - h\n",
    "            fmmh = loss_func(U, M, R, reg)\n",
    "            \n",
    "            M[j][k] = old_val\n",
    "            num_grad_m[j][k] = (fmph - fmmh) / (2 * h)\n",
    "    \n",
    "    return num_grad_u, num_grad_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient of U relative error 2.5957030021162005e-10\n",
      "Gradient of M relative error 8.20323831585007e-11\n",
      "\n",
      "Fully vectorized implementation\n",
      "\n",
      "Gradient of U relative error 2.595711175602241e-10\n",
      "Gradient of M relative error 8.20323831585007e-11\n"
     ]
    }
   ],
   "source": [
    "num_user = 3\n",
    "num_movie = 3\n",
    "lat_dim = 4\n",
    "reg = 0.5\n",
    "\n",
    "R = np.random.rand(num_user, num_movie)\n",
    "U = np.random.rand(num_user, lat_dim)\n",
    "M = np.random.randn(num_movie, lat_dim)\n",
    "\n",
    "np.dot(U, M.T)\n",
    "\n",
    "grad_u, grad_m = compute_grad(U, M, R, reg)\n",
    "num_grad_u, num_grad_m = compute_num_grad(U, M, R, loss, reg)\n",
    "\n",
    "print \"Gradient of U relative error %s\" % str(rel_error(grad_u, num_grad_u))\n",
    "print \"Gradient of M relative error %s\" % str(rel_error(grad_m, num_grad_m))\n",
    "\n",
    "print \"\\nFully vectorized implementation\\n\"\n",
    "grad_u, grad_m = compute_grad_vectorized(U, M, R, reg)\n",
    "print \"Gradient of U relative error %s\" % str(rel_error(grad_u, num_grad_u))\n",
    "print \"Gradient of M relative error %s\" % str(rel_error(grad_m, num_grad_m))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
